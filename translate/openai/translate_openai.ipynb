{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5284926\n",
      "12472936\n",
      "13999888\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import datasets\n",
    "\n",
    "with open(\"data/parallel/SARC_PARALLEL\", \"rb\") as file:\n",
    "    dataset_sarc = pickle.load(file)\n",
    "with open(\"data/parallel/ONION_PARALLEL\", \"rb\") as file:\n",
    "    dataset_onion = pickle.load(file)\n",
    "\n",
    "\n",
    "anc, res, lab, prob_ = dataset_sarc[\"slo_anc\"], dataset_sarc[\"slo_res\"], dataset_sarc[\"labels\"], dataset_sarc[\"prob\"]\n",
    "inputs, labels, prob = list(), list(), list()\n",
    "for a, r_, l_, p in zip(anc, res, lab, prob_):\n",
    "    for r, l in zip(r_, l_):\n",
    "        inputs.append(a+r)\n",
    "        labels.append(l)\n",
    "        prob.append(p)\n",
    "\n",
    "text, lab, prob_ = dataset_onion[\"slo\"], dataset_onion[\"labels\"], dataset_onion[\"prob\"]\n",
    "inputs += text\n",
    "labels += lab\n",
    "prob += prob_\n",
    "\n",
    "anc2, res2 = dataset_sarc[\"eng_anc\"], dataset_sarc[\"eng_res\"]\n",
    "\n",
    "l = 0\n",
    "for a in anc2:\n",
    "    l+=len(a)\n",
    "print(l)\n",
    "for r in res2:\n",
    "    l += sum([len(i) for i in r])\n",
    "print(l)\n",
    "\n",
    "\n",
    "\n",
    "inputs2 = list()\n",
    "for a, r_ in zip(anc2, res2):\n",
    "    for r in r_:\n",
    "        inputs2.append(a+\"; \"+r)\n",
    "text2 =dataset_onion[\"eng\"]\n",
    "inputs2 += text2\n",
    "\n",
    "for t in text2:\n",
    "    l += len(t)\n",
    "\n",
    "print(l)\n",
    "\n",
    "dataset = datasets.Dataset.from_dict({\"slo\":inputs, \"eng\":inputs2, \"label\":labels, \"prob\":prob})\n",
    "dataset.sort(column_names=\"prob\")\n",
    "dataset = dataset.remove_columns([\"prob\"])\n",
    "dataset = dataset.select(range(len(inputs)-100000, len(inputs))).shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"eng\"][:10]\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Translate to Slovene.\"},\n",
    "    {\"role\": \"user\", \"content\": dataset[\"eng\"][0]}\n",
    "  ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,\n",
       " ChatCompletion(id='chatcmpl-9lZ1GOQQNXftpSIaTqAGAVAKD13eS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Na kakšne načine filmi in TV oddaje ne prikažejo srednješolcev na realističen način? Ne organiziramo velikih zabav in se močno opijamo vsak vikend; To počnemo samo vsak drugi vikend!', role='assistant', function_call=None, tool_calls=None))], created=1721123058, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=72, prompt_tokens=54, total_tokens=126)))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "encodings = enc.encode(\"Translate to Slovene.\"+dataset[\"eng\"][0])\n",
    "len(encodings), completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def f(i):\n",
    "    return {\"custom_id\": f\"{i}\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o\", \"messages\": [{\"role\": \"system\", \"content\": \"Translate to Slovene.\"}, {\"role\": \"user\", \"content\": dataset[\"eng\"][i]}],\"max_tokens\": 1000}}\n",
    "\n",
    "\n",
    "\n",
    "with Pool(8) as p:\n",
    "    for _ in tqdm(p.imap_unordered(f, range(16)), total=16):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_r1gNxBf2oM53aYrb0dZ75UtD', completion_window='24h', created_at=1721132994, endpoint='/v1/chat/completions', input_file_id='file-MSkB9Zooj5bGNOxiConuRklJ', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1721219394, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'translation batch 1'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BATCH 1\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "# batch_input_file = client.files.create(file=open(\"batch1.jsonl\", \"rb\"), purpose=\"batch\")\n",
    "# batch_input_file_id = batch_input_file.id\n",
    "# client.batches.create(\n",
    "#     input_file_id=batch_input_file_id,\n",
    "#     endpoint=\"/v1/chat/completions\",\n",
    "#     completion_window=\"24h\",\n",
    "#     metadata={\n",
    "#       \"description\": \"translation batch 1\"\n",
    "#     }\n",
    "# )\n",
    "# BATCH1 batch_r1gNxBf2oM53aYrb0dZ75UtD file-l5A1sAyvQI1XzmZNhudfIk9l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_u3rpk4ZnoMTtW8Ndq86OOzwy', completion_window='24h', created_at=1721142339, endpoint='/v1/chat/completions', input_file_id='file-nRoZOxOE7ZtcxihZw9yte38T', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1721228739, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'translation batch 2'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI(api_key=\"\")\n",
    "batch_input_file = client.files.create(file=open(\"batch2.jsonl\", \"rb\"), purpose=\"batch\")\n",
    "batch_input_file_id = batch_input_file.id\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"translation batch 2\"\n",
    "    }\n",
    ")\n",
    "# BATCH2 batch_u3rpk4ZnoMTtW8Ndq86OOzwy file-w3EvIpoIOmTIal2QBk04oPH3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_szhrmjRxScxss0H2FtyZkbNa', completion_window='24h', created_at=1721142353, endpoint='/v1/chat/completions', input_file_id='file-vWKFVwfDj7kQXCRhs1wHNb7L', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1721228753, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'translation batch 3'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI(api_key=\"\")\n",
    "batch_input_file = client.files.create(file=open(\"batch3.jsonl\", \"rb\"), purpose=\"batch\")\n",
    "batch_input_file_id = batch_input_file.id\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"translation batch 3\"\n",
    "    }\n",
    ")\n",
    "# BATCH3 batch_szhrmjRxScxss0H2FtyZkbNa file-SrGv4yqXAXwcqOjztF6TjE2j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_njaPSZxKSN7OlIHDreMxxwJz', completion_window='24h', created_at=1721142382, endpoint='/v1/chat/completions', input_file_id='file-fumJZQNzxIBelmyP9dcEqvnO', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1721228782, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'translation batch 4'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI(api_key=\"\")\n",
    "batch_input_file = client.files.create(file=open(\"batch4.jsonl\", \"rb\"), purpose=\"batch\")\n",
    "batch_input_file_id = batch_input_file.id\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"translation batch 4\"\n",
    "    }\n",
    ")\n",
    "# BATCH4 batch_njaPSZxKSN7OlIHDreMxxwJz file-BnwE9xDlllDeNmDy1UxkJTWf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Batch](data=[Batch(id='batch_njaPSZxKSN7OlIHDreMxxwJz', completion_window='24h', created_at=1721142382, endpoint='/v1/chat/completions', input_file_id='file-fumJZQNzxIBelmyP9dcEqvnO', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1721147359, error_file_id=None, errors=None, expired_at=None, expires_at=1721228782, failed_at=None, finalizing_at=1721145602, in_progress_at=1721142399, metadata={'description': 'translation batch 4'}, output_file_id='file-BnwE9xDlllDeNmDy1UxkJTWf', request_counts=BatchRequestCounts(completed=25000, failed=0, total=25000)), Batch(id='batch_szhrmjRxScxss0H2FtyZkbNa', completion_window='24h', created_at=1721142353, endpoint='/v1/chat/completions', input_file_id='file-vWKFVwfDj7kQXCRhs1wHNb7L', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1721147303, error_file_id=None, errors=None, expired_at=None, expires_at=1721228753, failed_at=None, finalizing_at=1721145603, in_progress_at=1721142370, metadata={'description': 'translation batch 3'}, output_file_id='file-SrGv4yqXAXwcqOjztF6TjE2j', request_counts=BatchRequestCounts(completed=25000, failed=0, total=25000)), Batch(id='batch_u3rpk4ZnoMTtW8Ndq86OOzwy', completion_window='24h', created_at=1721142339, endpoint='/v1/chat/completions', input_file_id='file-nRoZOxOE7ZtcxihZw9yte38T', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1721147327, error_file_id=None, errors=None, expired_at=None, expires_at=1721228739, failed_at=None, finalizing_at=1721145582, in_progress_at=1721142350, metadata={'description': 'translation batch 2'}, output_file_id='file-w3EvIpoIOmTIal2QBk04oPH3', request_counts=BatchRequestCounts(completed=25000, failed=0, total=25000)), Batch(id='batch_r1gNxBf2oM53aYrb0dZ75UtD', completion_window='24h', created_at=1721132994, endpoint='/v1/chat/completions', input_file_id='file-MSkB9Zooj5bGNOxiConuRklJ', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1721137689, error_file_id=None, errors=None, expired_at=None, expires_at=1721219394, failed_at=None, finalizing_at=1721135833, in_progress_at=1721133009, metadata={'description': 'translation batch 1'}, output_file_id='file-l5A1sAyvQI1XzmZNhudfIk9l', request_counts=BatchRequestCounts(completed=25000, failed=0, total=25000))], object='list', first_id='batch_njaPSZxKSN7OlIHDreMxxwJz', last_id='batch_r1gNxBf2oM53aYrb0dZ75UtD', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "print(client.batches.list(limit=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(file_response)\n",
    "#file_response.write_to_file(\"batch1_out.jsonl\")\n",
    "file_response = client.files.content(\"file-w3EvIpoIOmTIal2QBk04oPH3\")\n",
    "file_response.write_to_file(\"batch2_out.jsonl\")\n",
    "\n",
    "file_response = client.files.content(\"file-SrGv4yqXAXwcqOjztF6TjE2j\")\n",
    "file_response.write_to_file(\"batch3_out.jsonl\")\n",
    "\n",
    "file_response = client.files.content(\"file-BnwE9xDlllDeNmDy1UxkJTWf\")\n",
    "file_response.write_to_file(\"batch4_out.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "translations = [None for _ in range(100000)]\n",
    "for x in range(1,5):\n",
    "    with open(f'batch{x}_out.jsonl', 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        index, text = int(result['custom_id']), result['response']['body']['choices'][0]['message']['content']\n",
    "        translations[index] = text\n",
    "\n",
    "\n",
    "translations\n",
    "import pickle\n",
    "with open(\"data/gpt/translations_\", \"wb\") as file:\n",
    "    pickle.dump(translations, file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\"slo\"])\n",
    "dataset = dataset.add_column(\"slo\", translations)  # type: ignore\n",
    "\n",
    "with open(\"data/parallel/combined-final\", \"wb\") as file:\n",
    "    pickle.dump(dataset[:], file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
